# ğŸ§  Eyeball Segmentation and Center Point Detection using nnUNet

## ğŸ“Œ Project Overview
This project uses **nnU-Net** to segment the **eyeball regions** in head CT scans, with the primary goal of enabling **automated head alignment**.  
By extracting the center points of both eyes and rotating the image to horizontally align them, we achieve standardized orientation for downstream tasks such as gaze estimation, navigation, or anatomical normalization.

- Manual labels were created using **3D Slicer**
- Model trained on **20 CT scans**, tested on **7 CT scans**
- **5-fold cross-validation** was used during training
- Dataset source: [CQ500 Dataset](http://15.206.3.216/dataset)
---

## ğŸ—‚ï¸ Folder Structure
```
project_root/
â”‚
â”œâ”€â”€ nnUNet_raw/
â”‚   â”œâ”€â”€ Dataset001_Eyeball/
â”‚   â”‚   â”œâ”€â”€ imagesTr/          # 20 training CT volumes (NIfTI format)
â”‚   â”‚   â”œâ”€â”€ labelsTr/          # 20 eyeball segmentation masks
â”‚   â”‚   â”œâ”€â”€ imagesTs/          # 7 test CT volumes
â”‚   â”‚   â””â”€â”€ dataset.json       # nnU-Net metadata
â”‚
â”œâ”€â”€ preprocess/
â”‚   â”œâ”€â”€ convert_dicom_to_nifti.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ results/
â”‚   â””â”€â”€ ...                    # Output predictions and metrics
â”‚
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Setup & Installation

```bash
conda create -n nnunet python=3.10 -y
conda activate nnunet

pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -e "git+https://github.com/MIC-DKFZ/nnUNet.git#egg=nnunet"
```

Set environment variables:
```bash
export nnUNet_raw_data_base="/path/to/nnUNet_raw"
export nnUNet_preprocessed="/path/to/nnUNet_preprocessed"
export RESULTS_FOLDER="/path/to/nnUNet_results"
```

---

## ğŸ§¾ Labeling Method

- Manual labeling was performed using **3D Slicer**.
- Both left and right eyeballs were annotated as a **single foreground class** (label: `1`).
- Labels were saved in **NIfTI (.nii.gz)** format and placed under `labelsTr/`.
- The **center point** of each eyeball was computed from the segmentation masks using a simple postprocessing step (e.g., centroid of connected components).

---

## âš™ï¸ Preprocessing

- CT volumes used for training were preprocessed to standardize window size and slice spacing across samples.
- No other preprocessing (e.g., cropping or intensity normalization) was applied.

---

## ğŸ§ª Training and Inference

### Training with 5-fold Cross Validation:
```bash
nnUNetv2_train 001 3d_fullres all
```

### Inference on test set:
```bash
nnUNetv2_predict -i /path/to/imagesTs \
                 -o /path/to/output \
                 -d 001 -c 3d_fullres -f 0
```

You can iterate `-f` from 0 to 4 for each fold if needed.

---

ğŸ” Post Processing

After model inference, we perform post-processing to extract meaningful anatomical information from the segmentation masks.

âœ”ï¸ Center Point Extraction
	â€¢	The center point of each eyeball is computed from the predicted mask using connected component analysis.
	â€¢	For each connected component, we calculate the centroid using tools like:
	â€¢	scipy.ndimage.center_of_mass
	â€¢	or skimage.measure.regionprops

âœ”ï¸ Rotation Based on Center Points
	â€¢	After extracting both eyeball center points, the image is rotated so that:
	â€¢	The line connecting the two centers becomes horizontal
	â€¢	The head is properly aligned with the vertical midline
	â€¢	This step ensures consistency and anatomical standardization across scans, which is especially important for alignment-sensitive tasks.

---

## ğŸ“Š Train Results
Below is the image of a rotated Brain CT, using the predicted eye mask. 
![Image](https://github.com/user-attachments/assets/fc01aa13-2363-4da8-a147-40e8a4f08996)
---

## ğŸ“š References

- [nnU-Net: Self-adapting Framework for U-Net-based Medical Image Segmentation](https://arxiv.org/abs/1809.10486)
- [3D Slicer](https://www.slicer.org/)
- [CQ500 Dataset](http://15.206.3.216/dataset)